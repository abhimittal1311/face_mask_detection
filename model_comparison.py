# -*- coding: utf-8 -*-
"""Model_Comparison.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a-Ro77ssiCeZsg7ZhC7d3wWu0pNw4kIy

Importing all necessary libraries
"""

import warnings
warnings.filterwarnings("ignore")
import os
import sklearn
import torchvision
import numpy
import torch
import matplotlib

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
import torch.optim as optim

from torch import nn
from torch.autograd import Variable
from torch.utils.data import DataLoader, Sampler, random_split
from torch.utils.data.sampler import SubsetRandomSampler
from sklearn.metrics import ConfusionMatrixDisplay

from torchvision import datasets
from torchvision.transforms import transforms
from torch.optim import Adam
import matplotlib.pyplot as plt
import numpy as np
from torch.utils.data import DataLoader

from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay

"""Mounting Google Drive and setting transform values"""

from google.colab import drive
drive.mount('/content/drive')

datadir = "/content/drive/MyDrive/Comp6721_Dataset/Final_Dataset" 

# set the transforms of pytorch with the mean and standard deviation of the dataset images.
trans = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize((128)), # get a patch of the input image in a square shape(h:32 x w:32)
    transforms.CenterCrop(60), transforms.ToTensor(), # Scale the image uniformly (maintain the image's aspect ratio)
    transforms.Normalize(mean=[0.6569, 0.5629, 0.5234],std=[0.4778, 0.4677, 0.4861])
    ])

# set the full path for the hosting directory of the images repository.
dataset_source = datasets.ImageFolder(datadir, transform=trans)

class Basic_Cell_Conv_Net(nn.Module): # Basic_Cell_Conv_Net
    
    def __init__(self, in_channels, out_channels):
        super(Basic_Cell_Conv_Net, self).__init__()  #Basic_Cell_Conv_Net
        # creating basic Conv2d neural unit
        self.conv_layer = nn.Conv2d(in_channels=in_channels, kernel_size=3, out_channels=out_channels, stride=1, padding=1)
        # Appling Batch Normalization.
        self.Batch_Normalization = nn.BatchNorm2d(num_features = out_channels)
        # applying LeakyReLU activation function.
        self.relu = nn.LeakyReLU(inplace=True)
        
    def forward(self, input):
        x_out = self.conv_layer(input)
        x_out = self.Batch_Normalization(x_out)
        x_out = self.relu(x_out)
        return x_out

class Model_Convolutional_Network(nn.Module):
    def __init__(self, output_classes):
        super(Model_Convolutional_Network, self).__init__()

        # Input layer (3x32).
        self.Basic_Cell_Conv_input = Basic_Cell_Conv_Net(in_channels=3, out_channels=32)
        self.pool_Max_1 = nn.MaxPool2d(kernel_size=2)

        # hidden layer 1 (32x32)
        self.Basic_Cell_Conv_Net_hidden_1 = Basic_Cell_Conv_Net(in_channels=32, out_channels=32)
        self.pool_Max_2 = nn.MaxPool2d(kernel_size=2)
        
        # hidden layer 2 (32x128)
        self.Basic_Cell_Conv_Net_hidden_2 = Basic_Cell_Conv_Net(in_channels=32, out_channels=128)
        self.pool_Max_3 = nn.MaxPool2d(kernel_size=2)

        # hidden layer 3 (128 x 128)
        self.Basic_Cell_Conv_Net_hidden_3 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)
        
        # Apply Average pooling before flatten.
        self.pool_avg = nn.AvgPool2d(kernel_size=4)
        
        # combining all created CNNs into a Sequential layers in sequence.
        self.net = nn.Sequential(self.Basic_Cell_Conv_input, 
                                 self.pool_Max_1,
                                 
                                 self.Basic_Cell_Conv_Net_hidden_1,
                                 self.pool_Max_2,
                                 
                                 self.Basic_Cell_Conv_Net_hidden_2, 
                                  self.pool_Max_3,
                                 
                                self.Basic_Cell_Conv_Net_hidden_3,

                                 self.pool_avg
                                 )
        
        # build the linear neural network.
        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),
            nn.Linear(128, 1000),
            nn.ReLU(inplace=True),
            nn.Linear(1000, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
            nn.Linear(in_features=128, out_features=output_classes)
            )
        
    def forward(self, input):
        _x_ = self.net(input)
        _x_ = _x_.view(-1, 128) # reshape the output of the conv neural network before fed into the linear network
        _x_ = self.fc_layer(_x_)
        return _x_

class Model_Convolutional_Network(nn.Module):
    
    def __init__(self, output_classes):
        super(Model_Convolutional_Network, self).__init__()
        # Creating modelCNNs layers with max pooling among.
        self.Basic_Cell_Conv_Net_1 = Basic_Cell_Conv_Net(in_channels=3, out_channels=128)
        self.Basic_Cell_Conv_Net_2 = Basic_Cell_Conv_Net(in_channels=128, out_channels=32)
        self.Basic_Cell_Conv_Net_3 = Basic_Cell_Conv_Net(in_channels=32, out_channels=32)

        self.pool_Max_1 = nn.MaxPool2d(kernel_size=2)

        self.Basic_Cell_Conv_Net_4 = Basic_Cell_Conv_Net(in_channels=32, out_channels=64)
        self.Basic_Cell_Conv_Net_5 = Basic_Cell_Conv_Net(in_channels=64, out_channels=64)

        self.pool_Max_2 = nn.MaxPool2d(kernel_size=2)
        self.Basic_Cell_Conv_Net_6 = Basic_Cell_Conv_Net(in_channels=64, out_channels=128)
        self.Basic_Cell_Conv_Net_7 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)

        self.pool_Max_3 = nn.MaxPool2d(kernel_size=2)

        self.Basic_Cell_Conv_Net_8 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)
        self.Basic_Cell_Conv_Net_9 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)
        
        # Apply Average pooling before flatten.
        self.pool_avg = nn.AvgPool2d(kernel_size=4)
        
        # combining all created neural units into a Sequential layer in sequence.
        self.net = nn.Sequential(self.Basic_Cell_Conv_Net_1, 
                                 self.Basic_Cell_Conv_Net_2,
                                 self.Basic_Cell_Conv_Net_3,
                                 self.pool_Max_1,
                                 self.Basic_Cell_Conv_Net_4,
                                 self.Basic_Cell_Conv_Net_5, 
                                 self.pool_Max_2,
                                 self.Basic_Cell_Conv_Net_6, 
                                 self.Basic_Cell_Conv_Net_7, 
                                  self.pool_Max_3,
                                self.Basic_Cell_Conv_Net_8,
                                self.Basic_Cell_Conv_Net_9,
                                 self.pool_avg
                                 )
        
        # build the linear neural network.
        self.fc_layer = nn.Sequential(
            nn.Dropout(p=0.1),
            nn.Linear(128, 1000),
            nn.ReLU(inplace=True),
            nn.Linear(1000, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.1),
            nn.Linear(in_features=128, out_features=output_classes)
            )
        
    def forward(self, input):
        _x_ = self.net(input)
        _x_ = _x_.view(-1, 128) # reshape the output of the conv neural network before fed into the linear network
        _x_ = self.fc_layer(_x_)
        return _x_

datadir = "/content/drive/MyDrive/Comp6721_Dataset/Final_Dataset" 

trans = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize((128)), # get a patch of the input image in a square shape(h:32 x w:32)
    transforms.CenterCrop(60), transforms.ToTensor(), # Scale the image uniformly (maintain the image's aspect ratio)
    transforms.Normalize(mean=[0.6569, 0.5629, 0.5234],std=[0.4778, 0.4677, 0.4861])
    ])


dataset_source = datasets.ImageFolder(datadir, transform=trans)
# # loading the images indexes which will be tested by the trained model.  
# testing_indexes =[503, 1399, 168, 204, 247, 1306, 1231, 1239, 185, 876, 1179, 1442, 24, 738, 452, 1987, 1344, 1417, 640, 1402, 1489, 1485, 266, 1892, 1290, 1088, 137, 1238, 1949, 548, 1493, 1333, 132, 1591, 862, 28, 382, 359, 289, 1353, 127, 1184, 621, 1449, 848, 809, 1089, 1242, 1973, 1352, 908, 1301, 1294, 1921, 164, 157, 1376, 1787, 954, 1660, 1687, 1786, 1408, 1865, 689, 1936, 1218, 209, 770, 1639, 50, 1008, 275, 118, 1731, 1762, 197, 1873, 4, 1772, 1939, 1275, 291, 1914, 1743, 1564, 49, 1763, 1315, 148, 1109, 1361, 1203, 762, 1095, 1846, 337, 952, 1042, 1515, 1244, 1580, 1547, 1750, 1853, 1421, 1127, 161, 133, 358, 1200, 380, 810, 1506, 977, 586, 1107, 1069, 981, 1983, 1481, 1444, 1567, 72, 130, 1345, 1970, 708, 1416, 495, 1295, 584, 669, 594, 175, 1335, 1615, 1673, 1828, 1535, 126, 456, 94, 328, 860, 81, 692, 171, 1424, 227, 1492, 1195, 600, 1566, 340, 607, 1988, 444, 15, 356, 1248, 900, 1031, 1380, 1860, 927, 772, 1719, 1958, 1073, 1349, 1737, 1164, 431, 1538, 831, 1604, 1562, 917, 1904, 1153, 125, 579, 79, 1800, 1269, 296, 1457, 1966, 1486, 857, 1211, 327, 188, 1836, 129, 530, 1797, 53, 656, 1047, 1010, 106, 1201, 1837, 1488, 205, 1435, 688, 303, 1713, 322, 1982, 56, 730, 507, 1929, 1553, 1490, 1062, 1097, 124, 1543, 1128, 682, 699, 1541, 1642, 715, 182, 1523, 1685, 302, 1582, 1187, 1311, 73, 1940, 339, 861, 162, 1661, 51, 468, 1350, 983, 237, 1113, 338, 1753, 52, 951, 1599, 1120, 634, 342, 1619, 1456, 1464, 1446, 1509, 1060, 201, 167, 355, 1049, 390, 941, 1316, 348, 620, 1484, 1522, 1106, 1959, 856, 1346, 349, 1146, 8, 1377, 136, 1955, 1847, 1215, 1649, 1742, 710, 1931, 1605, 1396, 1821, 433, 113, 1861, 1104, 1558, 3, 1668, 846, 1773, 783, 131, 1409, 1378, 884, 1205, 97, 1206, 993, 396, 784, 574, 454, 1932, 790, 198, 928, 556, 726, 892, 486, 473, 524, 430, 1241, 1083, 424, 723, 23, 1854, 1055, 613, 743, 801, 1021, 292, 84, 1177, 817, 1151, 153, 1620, 1584, 504, 405, 14, 1822, 429, 311, 1076, 922, 1284, 1684, 1672, 585, 518, 704, 1761, 915, 145, 1004, 1954, 399, 1502, 1108, 1068, 874, 899, 1617, 1830, 1257, 601, 1697, 878, 395, 821, 657, 1790, 514, 635, 469, 22, 1002, 1024, 417, 1656, 724, 1858, 895, 1474, 1136, 609, 1776, 1278, 1132, 1657, 1181, 1193, 1817, 480, 1273, 1434, 664, 658, 1044, 300, 1840, 369, 637, 516, 1395, 749, 1144, 1174, 1224, 1261, 1831, 412, 229, 38, 1518, 624, 1036, 1358, 1755, 170, 513, 1841, 1343, 1927, 946, 1654, 13, 1758, 1810, 215, 883, 1355, 1968, 1624, 1226, 703, 1652, 799, 1461, 782, 2000, 547, 1256, 492, 1013, 195, 913, 1708, 1610, 812, 1901, 222, 260, 660, 595, 69, 589, 1905, 1849, 1143, 1018, 490, 1895, 242, 1956, 1645, 1367, 852, 35, 463, 1879, 238, 1086, 1272, 1783, 1003, 1942, 231, 301, 1225, 858, 632, 803, 1938, 1698, 953, 938, 1807, 1347, 1255, 384, 1364, 691, 758, 663]


# testing_subset = SubsetRandomSampler(testing_indexes)
# testloader = torch.utils.data.DataLoader(dataset_source, sampler=testing_subset, num_workers=1)

indexes_values = list(range(len(dataset_source)))

training_testing_split = int(np.floor(0.75 * len(dataset_source))) # set the train split that is 75%
np.random.shuffle(indexes_values) # shuffling the indices values to balance the categories of the images used in training and testing phases. 
# Set the training and testing indices from the main dataset.
train_indexes, testing_indexes = indexes_values[:training_testing_split], indexes_values[training_testing_split:]

# Set the training and testing samples according to train_indexes and testing_indexes
# training_subset = SubsetRandomSampler(train_indexes)
testing_subset = SubsetRandomSampler(testing_indexes)

# loading the training and testing samples using torch library.
# trainloader = torch.utils.data.DataLoader(dataset_source, sampler=training_subset, batch_size=50, num_workers=1)
testloader = torch.utils.data.DataLoader(dataset_source, sampler=testing_subset)

output_classes = 5

PATH = "/content/drive/MyDrive/Comp6721_Dataset/12_4_11_no_Kfold_En_model.pth"

model = Model_Convolutional_Network(output_classes)
model.load_state_dict(torch.load(PATH),strict=False)

num_epochs = 20 # set the number of iterations for the training phase.
output_classes = 5 # set the number of output classes to be predicited for each data sample image.
learning_rate = 0.001 # set the learning rate for the training phase.

# Set the main directory path of the images dataset or repository used in training and testing the model.
#datadir = './full_data_set'

# set the transforms of pytorch with the mean and standard deviation of the dataset images.
trans = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize((128)), # get a patch of the input image in a square shape(h:32 x w:32)
    transforms.CenterCrop(60), transforms.ToTensor(), # Scale the image uniformly (maintain the image's aspect ratio)
    transforms.Normalize(mean=[0.6569, 0.5629, 0.5234],std=[0.4778, 0.4677, 0.4861])
    ])

# set the full path for the hosting directory of the images repository.
dataset_source = datasets.ImageFolder(datadir, transform=trans)

# set the count range of the dataset images to compute the training and testing split from the full dataset.
indexes_values = list(range(len(dataset_source)))

training_testing_split = int(np.floor(0.75 * len(dataset_source))) # set the train split that is 75%
np.random.shuffle(indexes_values) # shuffling the indices values to balance the categories of the images used in training and testing phases. 

# Set the training and testing indices from the main dataset.

train_indexes, testing_indexes = indexes_values[:training_testing_split], indexes_values[training_testing_split:]

# Set the training and testing samples according to train_indexes and testing_indexes
training_subset = SubsetRandomSampler(train_indexes)
testing_subset = SubsetRandomSampler(testing_indexes)

# loading the training and testing samples using torch library.
trainloader = torch.utils.data.DataLoader(dataset_source, sampler=training_subset, batch_size=50, num_workers=1)
testloader = torch.utils.data.DataLoader(dataset_source, sampler=testing_subset, num_workers=1)

model = Model_Convolutional_Network(output_classes)
criterion_fun = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)

total_step = len(trainloader)
training_y_pred= []
training_set_targets_ = []
for epoch in range(num_epochs):
    for i, (_images_, labels_) in enumerate(trainloader):
        training_set_targets_.append(labels_[0])
        
        _images_ = Variable(_images_)
        labels_ = Variable(labels_)
        
        resutls = model(_images_)
        loss = criterion_fun(resutls, labels_)
     
        # Backprop and optimisation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # Training accuracy
        training_total = labels_.size(0)
        
        _, predicted = torch.max(resutls.data, 1)
        training_y_pred.append(predicted.tolist()[0])
        
        correct = (predicted == labels_).sum().item()
        if (i + 1) % total_step == 0:
            print('Epoch [{}/{}], Step [{}/{}], TrainLoss: {:.2f}, Train Accuracy: {:.2f}%'
            .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), (correct / training_total) * 100))

"cell No. 9"
# saving the trained model

PATH = "Enhanced_model.pth"
# Save
torch.save(model.state_dict(), PATH)

y_pred = []
test_set_targets_ = []

model.eval()
with torch.no_grad():
    correct_hits = 0
    total_processed = 0
    
    for ii, (images__, labels__) in enumerate(testloader):
        test_set_targets_.append(labels__[0])
        test_outputs = model(images__)
        _, predicted = torch.max(test_outputs.data, 1)
        y_pred.append(predicted.tolist()[0])
        total_processed += labels__.size(0)
        correct_hits += (predicted == labels__).sum().item()

"""Variant without Dropout"""

trans = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize((128)), # get a patch of the input image in a square shape(h:32 x w:32)
    transforms.CenterCrop(60), transforms.ToTensor(), # Scale the image uniformly (maintain the image's aspect ratio)
    transforms.Normalize(mean=[0.6569, 0.5629, 0.5234],std=[0.4778, 0.4677, 0.4861])
    ])

# set the full path for the hosting directory of the images repository.
dataset_source = datasets.ImageFolder(datadir, transform=trans)

class Basic_Cell_Conv_Net(nn.Module): # Basic_Cell_Conv_Net
    
    def __init__(self, in_channels, out_channels):
        super(Basic_Cell_Conv_Net, self).__init__()  #Basic_Cell_Conv_Net
        # creating basic Conv2d neural unit
        self.conv_layer = nn.Conv2d(in_channels=in_channels, kernel_size=3, out_channels=out_channels, stride=1, padding=1)
        # Appling Batch Normalization.
        self.Batch_Normalization = nn.BatchNorm2d(num_features = out_channels)
        # applying LeakyReLU activation function.
        self.relu = nn.LeakyReLU(inplace=True)
        
    def forward(self, input):
        x_out = self.conv_layer(input)
        x_out = self.Batch_Normalization(x_out)
        x_out = self.relu(x_out)
        return x_out

class Model_Convolutional_Network_NoDropout(nn.Module):
    def __init__(self, output_classes):
        super(Model_Convolutional_Network_NoDropout, self).__init__()

        # Input layer (3x32).
        self.Basic_Cell_Conv_input = Basic_Cell_Conv_Net(in_channels=3, out_channels=32)
        self.pool_Max_1 = nn.MaxPool2d(kernel_size=2)

        # hidden layer 1 (32x32)
        self.Basic_Cell_Conv_Net_hidden_1 = Basic_Cell_Conv_Net(in_channels=32, out_channels=32)
        self.pool_Max_2 = nn.MaxPool2d(kernel_size=2)
        
        # hidden layer 2 (32x128)
        self.Basic_Cell_Conv_Net_hidden_2 = Basic_Cell_Conv_Net(in_channels=32, out_channels=128)
        self.pool_Max_3 = nn.MaxPool2d(kernel_size=2)

        # hidden layer 3 (128 x 128)
        self.Basic_Cell_Conv_Net_hidden_3 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)
        
        # Apply Average pooling before flatten.
        self.pool_avg = nn.AvgPool2d(kernel_size=4)
        
        # combining all created CNNs into a Sequential layers in sequence.
        self.net = nn.Sequential(self.Basic_Cell_Conv_input, 
                                 self.pool_Max_1,
                                 
                                 self.Basic_Cell_Conv_Net_hidden_1,
                                 self.pool_Max_2,
                                 
                                 self.Basic_Cell_Conv_Net_hidden_2, 
                                  self.pool_Max_3,
                                 
                                self.Basic_Cell_Conv_Net_hidden_3,

                                 self.pool_avg
                                 )
        
        # build the linear neural network.
        self.fc_layer = nn.Sequential(
          #  nn.Dropout(p=0.1),
            nn.Linear(128, 1000),
            nn.ReLU(inplace=True),
            nn.Linear(1000, 128),
            nn.ReLU(inplace=True),
            #nn.Dropout(p=0.1),
            nn.Linear(in_features=128, out_features=output_classes)
            )
        
    def forward(self, input):
        _x_ = self.net(input)
        _x_ = _x_.view(-1, 128) # reshape the output of the conv neural network before fed into the linear network
        _x_ = self.fc_layer(_x_)
        return _x_

class Model_Convolutional_Network_NoDropout(nn.Module):
    
    def __init__(self, output_classes):
        super(Model_Convolutional_Network_NoDropout, self).__init__()
        # Creating modelCNNs layers with max pooling among.
        self.Basic_Cell_Conv_Net_1 = Basic_Cell_Conv_Net(in_channels=3, out_channels=128)
        self.Basic_Cell_Conv_Net_2 = Basic_Cell_Conv_Net(in_channels=128, out_channels=32)
        self.Basic_Cell_Conv_Net_3 = Basic_Cell_Conv_Net(in_channels=32, out_channels=32)

        self.pool_Max_1 = nn.MaxPool2d(kernel_size=2)

        self.Basic_Cell_Conv_Net_4 = Basic_Cell_Conv_Net(in_channels=32, out_channels=64)
        self.Basic_Cell_Conv_Net_5 = Basic_Cell_Conv_Net(in_channels=64, out_channels=64)

        self.pool_Max_2 = nn.MaxPool2d(kernel_size=2)
        self.Basic_Cell_Conv_Net_6 = Basic_Cell_Conv_Net(in_channels=64, out_channels=128)
        self.Basic_Cell_Conv_Net_7 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)

        self.pool_Max_3 = nn.MaxPool2d(kernel_size=2)

        self.Basic_Cell_Conv_Net_8 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)
        self.Basic_Cell_Conv_Net_9 = Basic_Cell_Conv_Net(in_channels=128, out_channels=128)
        
        # Apply Average pooling before flatten.
        self.pool_avg = nn.AvgPool2d(kernel_size=4)
        
        # combining all created neural units into a Sequential layer in sequence.
        self.net = nn.Sequential(self.Basic_Cell_Conv_Net_1, 
                                 self.Basic_Cell_Conv_Net_2,
                                 self.Basic_Cell_Conv_Net_3,
                                 self.pool_Max_1,
                                 self.Basic_Cell_Conv_Net_4,
                                 self.Basic_Cell_Conv_Net_5, 
                                 self.pool_Max_2,
                                 self.Basic_Cell_Conv_Net_6, 
                                 self.Basic_Cell_Conv_Net_7, 
                                  self.pool_Max_3,
                                self.Basic_Cell_Conv_Net_8,
                                self.Basic_Cell_Conv_Net_9,
                                 self.pool_avg
                                 )
        
        # build the linear neural network.
        self.fc_layer = nn.Sequential(
           # nn.Dropout(p=0.1),
            nn.Linear(128, 1000),
            nn.ReLU(inplace=True),
            nn.Linear(1000, 128),
            nn.ReLU(inplace=True),
          #  nn.Dropout(p=0.1),
            nn.Linear(in_features=128, out_features=output_classes)
            )
        
    def forward(self, input):
        _x_ = self.net(input)
        _x_ = _x_.view(-1, 128) # reshape the output of the conv neural network before fed into the linear network
        _x_ = self.fc_layer(_x_)
        return _x_

trans = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize((128)), # get a patch of the input image in a square shape(h:32 x w:32)
    transforms.CenterCrop(60), transforms.ToTensor(), # Scale the image uniformly (maintain the image's aspect ratio)
    transforms.Normalize(mean=[0.6569, 0.5629, 0.5234],std=[0.4778, 0.4677, 0.4861])
    ])

datadir = "/content/drive/MyDrive/Comp6721_Dataset/Final_Dataset" 
dataset_source = datasets.ImageFolder(datadir, transform=trans)
# # loading the images indexes which will be tested by the trained model.  
# testing_indexes =[503, 1399, 168, 204, 247, 1306, 1231, 1239, 185, 876, 1179, 1442, 24, 738, 452, 1987, 1344, 1417, 640, 1402, 1489, 1485, 266, 1892, 1290, 1088, 137, 1238, 1949, 548, 1493, 1333, 132, 1591, 862, 28, 382, 359, 289, 1353, 127, 1184, 621, 1449, 848, 809, 1089, 1242, 1973, 1352, 908, 1301, 1294, 1921, 164, 157, 1376, 1787, 954, 1660, 1687, 1786, 1408, 1865, 689, 1936, 1218, 209, 770, 1639, 50, 1008, 275, 118, 1731, 1762, 197, 1873, 4, 1772, 1939, 1275, 291, 1914, 1743, 1564, 49, 1763, 1315, 148, 1109, 1361, 1203, 762, 1095, 1846, 337, 952, 1042, 1515, 1244, 1580, 1547, 1750, 1853, 1421, 1127, 161, 133, 358, 1200, 380, 810, 1506, 977, 586, 1107, 1069, 981, 1983, 1481, 1444, 1567, 72, 130, 1345, 1970, 708, 1416, 495, 1295, 584, 669, 594, 175, 1335, 1615, 1673, 1828, 1535, 126, 456, 94, 328, 860, 81, 692, 171, 1424, 227, 1492, 1195, 600, 1566, 340, 607, 1988, 444, 15, 356, 1248, 900, 1031, 1380, 1860, 927, 772, 1719, 1958, 1073, 1349, 1737, 1164, 431, 1538, 831, 1604, 1562, 917, 1904, 1153, 125, 579, 79, 1800, 1269, 296, 1457, 1966, 1486, 857, 1211, 327, 188, 1836, 129, 530, 1797, 53, 656, 1047, 1010, 106, 1201, 1837, 1488, 205, 1435, 688, 303, 1713, 322, 1982, 56, 730, 507, 1929, 1553, 1490, 1062, 1097, 124, 1543, 1128, 682, 699, 1541, 1642, 715, 182, 1523, 1685, 302, 1582, 1187, 1311, 73, 1940, 339, 861, 162, 1661, 51, 468, 1350, 983, 237, 1113, 338, 1753, 52, 951, 1599, 1120, 634, 342, 1619, 1456, 1464, 1446, 1509, 1060, 201, 167, 355, 1049, 390, 941, 1316, 348, 620, 1484, 1522, 1106, 1959, 856, 1346, 349, 1146, 8, 1377, 136, 1955, 1847, 1215, 1649, 1742, 710, 1931, 1605, 1396, 1821, 433, 113, 1861, 1104, 1558, 3, 1668, 846, 1773, 783, 131, 1409, 1378, 884, 1205, 97, 1206, 993, 396, 784, 574, 454, 1932, 790, 198, 928, 556, 726, 892, 486, 473, 524, 430, 1241, 1083, 424, 723, 23, 1854, 1055, 613, 743, 801, 1021, 292, 84, 1177, 817, 1151, 153, 1620, 1584, 504, 405, 14, 1822, 429, 311, 1076, 922, 1284, 1684, 1672, 585, 518, 704, 1761, 915, 145, 1004, 1954, 399, 1502, 1108, 1068, 874, 899, 1617, 1830, 1257, 601, 1697, 878, 395, 821, 657, 1790, 514, 635, 469, 22, 1002, 1024, 417, 1656, 724, 1858, 895, 1474, 1136, 609, 1776, 1278, 1132, 1657, 1181, 1193, 1817, 480, 1273, 1434, 664, 658, 1044, 300, 1840, 369, 637, 516, 1395, 749, 1144, 1174, 1224, 1261, 1831, 412, 229, 38, 1518, 624, 1036, 1358, 1755, 170, 513, 1841, 1343, 1927, 946, 1654, 13, 1758, 1810, 215, 883, 1355, 1968, 1624, 1226, 703, 1652, 799, 1461, 782, 2000, 547, 1256, 492, 1013, 195, 913, 1708, 1610, 812, 1901, 222, 260, 660, 595, 69, 589, 1905, 1849, 1143, 1018, 490, 1895, 242, 1956, 1645, 1367, 852, 35, 463, 1879, 238, 1086, 1272, 1783, 1003, 1942, 231, 301, 1225, 858, 632, 803, 1938, 1698, 953, 938, 1807, 1347, 1255, 384, 1364, 691, 758, 663]


# testing_subset = SubsetRandomSampler(testing_indexes)
# testloader = torch.utils.data.DataLoader(dataset_source, sampler=testing_subset, num_workers=1)

indexes_values = list(range(len(dataset_source)))

training_testing_split = int(np.floor(0.75 * len(dataset_source))) # set the train split that is 75%
np.random.shuffle(indexes_values) # shuffling the indices values to balance the categories of the images used in training and testing phases. 
# Set the training and testing indices from the main dataset.
train_indexes, testing_indexes = indexes_values[:training_testing_split], indexes_values[training_testing_split:]

# Set the training and testing samples according to train_indexes and testing_indexes
# training_subset = SubsetRandomSampler(train_indexes)
testing_subset = SubsetRandomSampler(testing_indexes)

# loading the training and testing samples using torch library.
# trainloader = torch.utils.data.DataLoader(dataset_source, sampler=training_subset, batch_size=50, num_workers=1)
testloader = torch.utils.data.DataLoader(dataset_source, sampler=testing_subset)

output_classes = 5

PATH = PATH = "/content/drive/MyDrive/Comp6721_Dataset/12_4_11_no_Kfold_En_model.pth"

model = Model_Convolutional_Network(output_classes)
model.load_state_dict(torch.load(PATH),strict=False)

num_epochs = 20 # set the number of iterations for the training phase.
output_classes = 5 # set the number of output classes to be predicited for each data sample image.
learning_rate = 0.001 # set the learning rate for the training phase.

# Set the main directory path of the images dataset or repository used in training and testing the model.
datadir = "/content/drive/MyDrive/Comp6721_Dataset/Final_Dataset"

# set the transforms of pytorch with the mean and standard deviation of the dataset images.
trans = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.Resize((128)), # get a patch of the input image in a square shape(h:32 x w:32)
    transforms.CenterCrop(60), transforms.ToTensor(), # Scale the image uniformly (maintain the image's aspect ratio)
    transforms.Normalize(mean=[0.6569, 0.5629, 0.5234],std=[0.4778, 0.4677, 0.4861])
    ])

# set the full path for the hosting directory of the images repository.
dataset_source = datasets.ImageFolder(datadir, transform=trans)

# set the count range of the dataset images to compute the training and testing split from the full dataset.
indexes_values = list(range(len(dataset_source)))

training_testing_split = int(np.floor(0.75 * len(dataset_source))) # set the train split that is 75%
np.random.shuffle(indexes_values) # shuffling the indices values to balance the categories of the images used in training and testing phases. 

# Set the training and testing indices from the main dataset.

train_indexes, testing_indexes = indexes_values[:training_testing_split], indexes_values[training_testing_split:]

# Set the training and testing samples according to train_indexes and testing_indexes
training_subset = SubsetRandomSampler(train_indexes)
testing_subset = SubsetRandomSampler(testing_indexes)

# loading the training and testing samples using torch library.
trainloader = torch.utils.data.DataLoader(dataset_source, sampler=training_subset, batch_size=50, num_workers=1)
testloader = torch.utils.data.DataLoader(dataset_source, sampler=testing_subset, num_workers=1)

model = Model_Convolutional_Network_NoDropout(output_classes)
criterion_fun = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0001)

total_step = len(trainloader)
training_y_pred= []
training_set_targets_ = []
for epoch in range(num_epochs):
    for i, (_images_, labels_) in enumerate(trainloader):
        training_set_targets_.append(labels_[0])
        
        _images_ = Variable(_images_)
        labels_ = Variable(labels_)
        
        resutls = model(_images_)
        loss = criterion_fun(resutls, labels_)
     
        # Backprop and optimisation
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        # Training accuracy
        training_total = labels_.size(0)
        
        _, predicted = torch.max(resutls.data, 1)
        training_y_pred.append(predicted.tolist()[0])
        
        correct = (predicted == labels_).sum().item()
        if (i + 1) % total_step == 0:
            print('Epoch [{}/{}], Step [{}/{}], TrainLoss: {:.2f}, Train Accuracy: {:.2f}%'
            .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), (correct / training_total) * 100))

# saving the trained model

PATH = "No_Dropout.pth"
# Save
torch.save(model.state_dict(), PATH)

y_pred = []
test_set_targets_ = []

model.eval()
with torch.no_grad():
    correct_hits = 0
    total_processed = 0
    
    for ii, (images__, labels__) in enumerate(testloader):
        test_set_targets_.append(labels__[0])
        test_outputs = model(images__)
        _, predicted = torch.max(test_outputs.data, 1)
        y_pred.append(predicted.tolist()[0])
        total_processed += labels__.size(0)
        correct_hits += (predicted == labels__).sum().item()

accuracy = accuracy_score(test_set_targets_, y_pred) 
precision = precision_score(test_set_targets_, y_pred, average='macro')
recall = recall_score(test_set_targets_, y_pred, average='macro')
f1 = f1_score(test_set_targets_, y_pred, average='macro')
c_matrix = confusion_matrix(test_set_targets_, y_pred)
print("---------------------------")
print("Testing / Evaluation stage:-")
print("---------------------------")
print("testing accuracy : ", accuracy)
print("testing precision : ", precision)
print("testing recall : ", recall)
print("testing f1_score : ", f1)
print()
print()
print("---------------------------")
print("Testing / Classification report results:-")
print("---------------------------")

# printing the dataset categories and assigned indexes
category_classes = dict((v,k) for k,v in dataset_source.class_to_idx.items())
for i in range (len(category_classes)):
    print(f"{i}:", category_classes[i])

# Print the classification_report
print("---------------------------")
print(classification_report(test_set_targets_, y_pred))
print("---------------------------")

print("---Testing / Confusion Matrix---:-")
# printing the dataset categories and assigned indexes
category_classes = dict((v,k) for k,v in dataset_source.class_to_idx.items())
for i in range (len(category_classes)):
    print(f"{i}:", category_classes[i])

# Showing the Confusion Matrix of the testing Phase
confusion_m_test = confusion_matrix(test_set_targets_, y_pred)
ConfusionMatrixDisplay(confusion_m_test, display_labels=[0, 1, 2, 3, 4]).plot()
plt.show()

